{
 "cells": [
  {
   "source": [
    "## Need to set image_path and model_path variables, are near the end of the notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path:str):\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        raise OSError('Path: {0} does not exist'.format(path))\n",
    "        \n",
    "    with open(os.path.join(path, 'settings.json')) as setting_file:\n",
    "        settings = json.load(setting_file)\n",
    "        \n",
    "    # load correct model\n",
    "    net = None\n",
    "    if settings['model'] == 'alexnet':\n",
    "        net = models.alexnet()\n",
    "        net.classifier[6] = nn.Linear(in_features=4096, out_features=7, bias=True)\n",
    "    elif settings['model'] == 'vgg11':\n",
    "        net = models.vgg11_bn()\n",
    "        net.classifier[6] = nn.Linear(in_features=4096, out_features=7, bias=True)\n",
    "    elif settings['model'] == 'vgg':\n",
    "        net = models.vgg19_bn()\n",
    "        net.classifier[6] = nn.Linear(in_features=4096, out_features=7, bias=True)\n",
    "    elif settings['model'] == 'resnet':\n",
    "        net = models.resnet18()\n",
    "        net.fc = nn.Linear(in_features=512, out_features=7, bias=True)\n",
    "    elif settings['model'] == 'densenet':\n",
    "        net = models.densenet121()\n",
    "        net.classifier = nn.Linear(in_features=1024, out_features=7, bias=True)\n",
    "        \n",
    "    net.load_state_dict(torch.load(os.path.join(path, 'final_model')))    \n",
    "    settings['net'] = net\n",
    "    \n",
    "    # load in loss information\n",
    "    settings['t_loss'] = np.load(os.path.join(path, 'train_loss.npy'))\n",
    "    settings['v_loss'] = np.load(os.path.join(path, 'valid_loss.npy'))\n",
    "    \n",
    "    # load predictions \n",
    "    settings['test_preds'] = np.load(os.path.join(path, 'test_predictions.npy'))\n",
    "    \n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plt_model(info:dict):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(list(range(1, info['num_epochs']+1)), info['t_loss'], label='Training Loss')\n",
    "    plt.plot(list(range(1, info['num_epochs']+1)), info['v_loss'], label='Validation Loss')\n",
    "\n",
    "    plt.title('Loss Over Training Epochs')\n",
    "    plt.ylabel('Cross Entropy Loss')\n",
    "    plt.xlabel('Epoch Number')\n",
    "\n",
    "    plt.xticks(np.linspace(0, info['num_epochs'], 11))\n",
    "    plt.yticks(np.linspace(0, np.around(np.max(info['v_loss']), 2) *1.1, 8))\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/lr-005.vgg.model//' # set this path to the model you want to run\n",
    "model_info = load_model(model_path)\n",
    "plt_model(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(info:dict, image:str):\n",
    "    image = cv2.cvtColor(cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2RGB)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.Resize(size=(224,224))(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    \n",
    "    plt.imshow(image[0].permute(1, 2, 0))\n",
    "        \n",
    "    return info['net'](image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "image_path = './assets/r_neutral.png' # set this to the path of the image you want to generate a prediction for\n",
    "scores = run_prediction(model_info, image_path).detach().numpy().squeeze()\n",
    "print(scores)\n",
    "\n",
    "emote = np.argmax(scores)\n",
    "\n",
    "if emote == 0:\n",
    "    print('Angry')\n",
    "elif emote == 1:\n",
    "    print('Disgust')\n",
    "elif emote == 2:\n",
    "    print('Fear')\n",
    "elif emote == 3:\n",
    "    print('Happy')\n",
    "elif emote == 4:\n",
    "    print('Sad')\n",
    "elif emote == 5:\n",
    "    print('Surprise')\n",
    "elif emote == 6:\n",
    "    print('Neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}